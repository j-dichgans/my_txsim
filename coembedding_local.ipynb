{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from anndata import AnnData\n",
    "import scanpy as sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_exp0 = ad.read_h5ad('C:/Users/mdichgan/Documents/Helmholtz/send_to_Jakob/spatial/counts_CPc_exp0_BA28.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(adata_exp0)\n",
    "# sc.pp.log1p(adata_exp0)\n",
    "adata_exp0.layers[\"lognorm\"] = adata_exp0.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_Yao = ad.read_h5ad(\n",
    "    'C:/Users/mdichgan/Documents/Helmholtz/send_to_Jakob/sc/Yao_150kcells_subsample_with_annotations_sparse_subset.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AnnData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_modality_ratio_score\u001b[39m(adata_st: AnnData, adata_sc: AnnData, obs_key: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcelltype\u001b[39m\u001b[39m\"\u001b[39m, k: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m45\u001b[39m):\n\u001b[0;32m      2\u001b[0m     adata_st\u001b[39m.\u001b[39mobs[\u001b[39m\"\u001b[39m\u001b[39mmodality\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mspatial\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m     adata_sc\u001b[39m.\u001b[39mobs[\u001b[39m\"\u001b[39m\u001b[39mmodality\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msc\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AnnData' is not defined"
     ]
    }
   ],
   "source": [
    "def get_modality_ratio_score(adata_st: AnnData, adata_sc: AnnData, obs_key: str = \"celltype\", k: int = 45):\n",
    "    adata_st.obs[\"modality\"] = \"spatial\"\n",
    "    adata_sc.obs[\"modality\"] = \"sc\"\n",
    "    adata = ad.concat([adata_st, adata_sc], join='inner')  #wieso inner join?\n",
    "\n",
    "    # Set counts to log norm data\n",
    "    adata.X = adata.layers[\"lognorm\"]\n",
    "    \n",
    "    # Calculate PCA (Note: we could also think about pca per cell type...)\n",
    "    assert (adata.obsm is None) or ('X_pca' not in adata.obsm), \"PCA already exists.\"\n",
    "    sc.tl.pca(adata)\n",
    "    \n",
    "    # get cell type groups\n",
    "    sc_cts = set(adata_sc.obs[\"celltype\"].cat.categories)\n",
    "    st_cts = set(adata_st.obs[\"celltype\"].cat.categories)\n",
    "    shared_cts = list(sc_cts.intersection(st_cts))          #welche celltypes verwenden, wieso diese?\n",
    "\n",
    "    # Get ratio per shared cell type\n",
    "    df = pd.DataFrame(columns=[\"celltype\",\"cell_id\",\"ratio\",\"exp_val\",\"score\"])\n",
    "    for ct in shared_cts:\n",
    "        # enough_cells = (adata.obs.loc[adata.obs[obs_key]==ct,\"modality\"].value_counts() > (ct_filter_factor * k)).all()     #drinlassen, Faktor 2\n",
    "        a = adata[adata.obs[obs_key]==ct]\n",
    "        exp_val = (a.obs.loc[a.obs[\"modality\"]==\"sc\"].shape[0])/a.obs.shape[0]\n",
    "        sc.pp.neighbors(a,n_neighbors=k)\n",
    "        G = nx.Graph(incoming_graph_data=a.obsp[\"connectivities\"])\n",
    "        nx.set_node_attributes(G, {i:a.obs[\"modality\"].values[i] for i in range(G.number_of_nodes())}, \"modality\")    #wie Knoten nummer?\n",
    "        # scores[ct] = np.clip(-nx.attribute_assortativity_coefficient(G, \"modality\") + 1, 0, 1)\n",
    "        for cell in G.nodes():\n",
    "            number_modality_sc = sum(1 for neighbor in G.neighbors(cell) if G.nodes[\"cell\"][\"modality\"]==\"sc\")\n",
    "            total_cells = G.degree(cell)\n",
    "            f = lambda x: 0 if x<= 0 or x>=1 else (x/exp_val if x>0 and x<=exp_val else x/(exp_val-1)+1/(1-exp_val))\n",
    "            #clip am ende\n",
    "            ratio = number_modality_sc/total_cells\n",
    "            score = f(ratio) #vektorisieren am Ende\n",
    "\n",
    "            # if total_cells != 0:              #0 nicht mÃ¶glich? immer k?\n",
    "            #     ratio = number_modality_sc / total_cells\n",
    "            # else:\n",
    "            #     ratio = 0        #no neighbors\n",
    "            df.append({\"cell_id\": \"cell_id\", \"celltype\": ct, \"ratio\": ratio, \"exp_val\":exp_val, \"score\": score})  #wie machen mit cell_id? ineffizient\n",
    "            #df aus liste an listen\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test get_modality_ratio_score\n",
    "get_modality_ratio_score(adata_exp0, adata_Yao)       #key error: lognorm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "txsim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0177e28d6b1befb957bf45cd3059bda73a45ca5987be779c0bf4fe7c5743d6a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
